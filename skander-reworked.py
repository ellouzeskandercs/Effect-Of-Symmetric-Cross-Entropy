# -*- coding: utf-8 -*-
"""Projet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hPxtmcnOk7RPQeYkGoNYqFTmxSMfIP4U

#Import Libraires
"""

import tensorflow as tf
import numpy as np
import math
import keras.backend as K
import matplotlib.pyplot as plt
import tensorflow.keras.backend as K

"""#Download Data"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)

x_train = x_train / 255
x_test = x_test / 255

x_train = x_train[:100,:,:,:]
y_train = y_train[:100,:]

"""#Define The model"""

model = tf.keras.Sequential([
tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer="he_normal", name='block1_conv1'),
tf.keras.layers.BatchNormalization(momentum=0.99,epsilon=0.001),
tf.keras.layers.Activation('relu'),
tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer="he_normal", name='block1_conv2'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu'),
tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'),
tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer="he_normal", name='block2_conv1'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu'),
tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer="he_normal", name='block2_conv2'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu'),
tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'),
tf.keras.layers.Conv2D(196, (3, 3), padding='same', kernel_initializer="he_normal", name='block3_conv1'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu'),
tf.keras.layers.Conv2D(196, (3, 3), padding='same', kernel_initializer="he_normal", name='block3_conv2'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu'),
tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'),
tf.keras.layers.Flatten(name='flatten'),
tf.keras.layers.Dense(256, kernel_initializer="he_normal", kernel_regularizer= tf.keras.regularizers.l2(0.01), bias_regularizer=tf.keras.regularizers.l2(0.01), name='fc1'),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation('relu', name='lid'),
tf.keras.layers.Dense(10, kernel_initializer="he_normal"),
tf.keras.layers.Activation(tf.nn.softmax, name="softmax")
])

def step_decay(epoch):
  initial_lrate = 0.01
  drop = 0.1
  epochs_drop = 40
  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))
  return lrate
class LossHistory(tf.keras.callbacks.Callback):
  def on_train_begin(self, logs={}):
    self.losses = []
    self.lr = []

  def on_epoch_end(self, batch, logs={}):
    self.losses.append(logs.get('loss'))
    self.lr.append(step_decay(len(self.losses)))

model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0001, nesterov=False),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))

loss_history = LossHistory()
lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)
H = model.fit(x_train,y_train, epochs=2,  validation_data= (x_test, y_test),callbacks=[loss_history, lrate])

predicted_prob = model.predict(x_train)
mean = np.mean(predicted_prob, axis=0)

print("predicitions on image 1" + predicted_prob[1])
print("sum of predictions should equal 1: " + np.sum(predicted_prob[1]))
print("mean of all predictions for all 10 categories: " + mean)
print("should equal 1: " + np.sum(mean))